{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Classifier Walkthrough\n",
    "\n",
    "Adapted from Google Keras code example [Image classification from scratch](https://keras.io/examples/vision/image_classification_from_scratch/)\n",
    "\n",
    " - Load libraries\n",
    " - Getting the data\n",
    " - Preprocessing\n",
    "    - Standard image size\n",
    "    - Splitting to train/test\n",
    " - Train a CNN and evaluate the results\n",
    " - Try the model on a new data source\n",
    "\n",
    " ## Remember first\n",
    " 1. Activate a virtual environment `conda env` or `source .venv/bin/activate`\n",
    " 2. `pip install -r requirements.txt` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# %pip install -r ../requirements.txt -q\n",
    "# %pip install --upgrade numpy matplotlib pydot tensorflow\n",
    "\n",
    "# (just for Christopher)\n",
    "# !apt install libcudnn8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pydot # NOTE: need graphviz installed in the system\n",
    "import hashlib\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "\n",
    "# Constants\n",
    "IMAGE_SIZE = (180, 180)\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 3\n",
    "ZIP_HASH = 'eedec42a8a363b8ff299a0f2d6eedadafc3af3e7'\n",
    "MODEL_PATH = 'models/animals.h5'\n",
    "DONT_REBUILD = True\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 2 for most warnings, 3 to suppress all warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the image datasets\n",
    "\n",
    "All image datasets will be stored in the `3-image_classification/animals` folder\n",
    "\n",
    "## Option 1 - download zip from data.badmath.org\n",
    "\n",
    "This is enabled in the next cell.\n",
    "\n",
    "1. Download zip from data.badmath.org\n",
    "2. Unzip folder\n",
    "3. Delete zip file\n",
    "\n",
    "\n",
    "## Option 2 - manual download from kaggle\n",
    "\n",
    "This will take some downloading, unzipping, and moving/renaming files and folders.\n",
    "\n",
    "### \"Cat and Dog\"\n",
    "1. Download the dataset from https://www.kaggle.com/datasets/tongpython/cat-and-dog\n",
    "2. Move the zip into the `animals` folder\n",
    "3. Unzip it, I've called the folder `animals/cat_and_dog`\n",
    "4. You should have images such as `animals/cat_and_dog/test_set/cats/cat.4001.jpg`\n",
    "\n",
    "### \"Animal Image Dataset\"\n",
    "1. Download the dataset from https://www.kaggle.com/datasets/ashishsaxena2209/animal-image-datasetdog-cat-and-panda\n",
    "2. Move the zip into the `animals` folder\n",
    "3. Unzip it, I've called the folder `animals/animal_images`\n",
    "4. You should have images such as `animals/animal_images/cats/cats_00001.jpg`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download image datasets\n",
    "\n",
    "# Skip this if you've already got a directory called 'animals' (e.g. if you've run this before)\n",
    "if not os.path.exists('animals'):\n",
    "    # Use curl to download the zip if it's not already there\n",
    "    if not os.path.exists('animals.zip'):\n",
    "        !curl -L -o animals.zip 'https://data.badmath.org/animals.zip'\n",
    "        \n",
    "    \n",
    "    hash = hashlib.sha1(open('animals.zip', 'rb').read()).hexdigest()\n",
    "    if (hash == ZIP_HASH):\n",
    "        print('✅ Download hash validated')\n",
    "    else:\n",
    "        raise Exception('❌ ERROR: Download hash does not match!')\n",
    "\n",
    "\n",
    "    # Unzip the downloaded file into `animals`\n",
    "    os.mkdir('animals')\n",
    "    shutil.unpack_archive('animals.zip', 'animals')\n",
    "\n",
    "    os.remove('animals.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for corrupted images\n",
    "train = 'animals/cat_and_dog/training_set/'\n",
    "valid = 'animals/cat_and_dog/test_set/'\n",
    "world = 'animals/animal_images/'\n",
    "\n",
    "num_skipped = 0\n",
    "for data_dir in (train, valid, world):\n",
    "    for animal in os.listdir(data_dir):\n",
    "        if os.path.isdir(os.path.join(data_dir, animal)):\n",
    "            folder_path = os.path.join(data_dir, animal)\n",
    "            for fname in os.listdir(folder_path):\n",
    "                fpath = os.path.join(folder_path, fname)\n",
    "                try:\n",
    "                    fobj = open(fpath, \"rb\")\n",
    "                    is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "                finally:\n",
    "                    fobj.close()\n",
    "\n",
    "                if not is_jfif:\n",
    "                    num_skipped += 1\n",
    "                    print(\"Deleted %s\" % fpath)\n",
    "                    # Delete corrupted image\n",
    "                    os.remove(fpath)\n",
    "\n",
    "\n",
    "print(\"Deleted %d images\" % num_skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the class names\n",
    "class_names = os.listdir(train)\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train,\n",
    "    labels='inferred',\n",
    "    subset=None,\n",
    "    seed=1337,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "train_ds = train_ds.map(lambda x, y: (x, tf.one_hot(y, NUM_CLASSES)))\n",
    "\n",
    "valid_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    valid,\n",
    "    labels='inferred',\n",
    "    subset=None,\n",
    "    seed=1337,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "valid_ds = valid_ds.map(lambda x, y: (x, tf.one_hot(y, NUM_CLASSES)))\n",
    "\n",
    "\n",
    "world_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    world,\n",
    "    labels='inferred',\n",
    "    subset=None,\n",
    "    seed=1337,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "world_ds = world_ds.map(lambda x, y: (x, tf.one_hot(y, NUM_CLASSES)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[tf.argmax(labels[i])])\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum and maximum dimensions of images in the training set\n",
    "min_height = 9999\n",
    "min_width = 9999\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    for image in images:\n",
    "        height, width, _ = image.shape\n",
    "        if height < min_height:\n",
    "            min_height = height\n",
    "        if width < min_width:\n",
    "            min_width = width\n",
    "\n",
    "print(\"Minimum training dimensions:\", min_height, \"x\", min_width)\n",
    "\n",
    "# Find the minimum and maximum dimensions of images in the validation set\n",
    "min_height = 9999\n",
    "min_width = 9999\n",
    "\n",
    "for images, labels in valid_ds:\n",
    "    for image in images:\n",
    "        height, width, _ = image.shape\n",
    "        if height < min_height:\n",
    "            min_height = height\n",
    "        if width < min_width:\n",
    "            min_width = width\n",
    "\n",
    "print(\"Minimum validation dimensions:\", min_height, \"x\", min_width)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model\n",
    "\n",
    "This code defines a convolutional neural network (CNN) using the Keras library. The network architecture consists of multiple blocks of separable convolutional layers, with residual connections between the blocks. The last layer is a dense layer with either sigmoid or softmax activation, depending on the number of classes. The model is created by calling the make_model function with the input shape and number of classes as arguments, and the resulting model is plotted using keras.utils.plot_model.\n",
    "\n",
    "This is a simplified version of the Xception architecture (https://arxiv.org/abs/1610.02357).\n",
    "\n",
    "Here is a quick description of the *layers* in our neural network:\n",
    " - `keras.Input(shape=input_shape)` creates an input layer with the specified input shape.\n",
    " - `layers.Rescaling(1.0 / 255)` rescales the input values by dividing them by 255.\n",
    " - `layers.Conv2D(128, 3, strides=2, padding=\"same\")` creates a 2D convolutional layer with 128 filters, a kernel size of 3x3, a stride of 2, and same padding.\n",
    " - `layers.BatchNormalization()` normalizes the outputs of the previous layer to speed up training and reduce overfitting.\n",
    " - `layers.Activation(\"relu\")` applies the ReLU activation function to the previous layer's outputs.\n",
    " - `layers.SeparableConv2D(size, 3, padding=\"same\")` creates a depthwise separable convolutional layer with size filters, a kernel size of 3x3, and same padding.\n",
    " - `layers.MaxPooling2D(3, strides=2, padding=\"same\")` applies max pooling to the previous layer's outputs, reducing their size by a factor of 2.\n",
    " - `layers.Conv2D(size, 1, strides=2, padding=\"same\")` creates a 2D convolutional layer with size filters, a kernel size of 1x1, a stride of 2, and same padding.\n",
    " - `layers.add([x, residual])` adds the outputs of the previous layer and the residual layer.\n",
    " - `layers.GlobalAveragePooling2D()` calculates the average of each feature map in the previous layer's outputs.\n",
    " - `layers.Dropout(0.5)` randomly drops out 50% of the previous layer's outputs during training to reduce overfitting.\n",
    " - `layers.Dense(units, activation=activation)` creates a fully connected layer with units output nodes and the specified activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model\n",
    "# This is a simplified version of the Xception architecture (https://arxiv.org/abs/1610.02357).\n",
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    # Load the saved model\n",
    "    model = keras.models.load_model(MODEL_PATH)\n",
    "    \n",
    "else:\n",
    "    if DONT_REBUILD:\n",
    "        !curl -L -o {MODEL_PATH} 'https://data.badmath.org/animals.h5'\n",
    "    else:\n",
    "        model = make_model(input_shape=IMAGE_SIZE + (3,), num_classes=NUM_CLASSES)\n",
    "\n",
    "        # Uncomment to show model summary plot\n",
    "        # keras.utils.plot_model(model, show_shapes=True)\n",
    "\n",
    "        epochs = 25\n",
    "\n",
    "        callbacks = [\n",
    "            keras.callbacks.ModelCheckpoint(\"checkpoints/save_at_{epoch}.keras\"),\n",
    "        ]\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(1e-3),\n",
    "            # loss=\"binary_crossentropy\",\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            validation_data=valid_ds,\n",
    "        )\n",
    "\n",
    "        # Save the model\n",
    "        model.save(MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.test.is_built_with_cuda())   # True if TensorFlow was built with CUDA support\n",
    "print(tf.test.is_built_with_cudnn())  # True if TensorFlow was built with CuDNN support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with 100% more plotting!\n",
    "# Plot the learning curves\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(valid_ds)\n",
    "print(f\"Validation loss: {val_loss:.2f}\")\n",
    "print(f\"Validation accuracy: {val_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the (cat, dog, panda) dataset\n",
    "world_ds = world_ds.prefetch(buffer_size=32)\n",
    "model.evaluate(world_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on a new image\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    world + 'pandas/panda_00016.jpg',\n",
    "    target_size=IMAGE_SIZE\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "class_index = tf.argmax(predictions, axis=1)[0]\n",
    "score = float(predictions[0][class_index])\n",
    "\n",
    "print(f\"This image is a {class_names[class_index]} with a probability of {100 * score:.2f}%.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well does the model perform on the (cat, dog, panda) dataset? Especially on the pandas?!?\n",
    "\n",
    "# Get list of all panda image file paths\n",
    "panda_paths = glob.glob(world + 'pandas/*.jpg')\n",
    "\n",
    "# Randomly select 9 panda images\n",
    "sample_panda_paths = random.sample(panda_paths, 9)\n",
    "\n",
    "# Create subplot for each image\n",
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "\n",
    "# Loop through each image and its corresponding subplot\n",
    "for i, path in enumerate(sample_panda_paths):\n",
    "    img = keras.preprocessing.image.load_img(path, target_size=IMAGE_SIZE)\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "    predictions = model.predict(img_array)\n",
    "    score = predictions[0]\n",
    "    class_names = ['cat', 'dog']\n",
    "    class_index = score.argmax()\n",
    "    class_name = class_names[class_index]\n",
    "    prob = score[class_index]\n",
    "    axs[i//3][i%3].imshow(img_array[0]/255.)\n",
    "    axs[i//3][i%3].set_title(f\"{class_name}: {prob:.2f}\")\n",
    "    axs[i//3][i%3].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
