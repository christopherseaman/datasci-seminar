{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Classifier Walkthrough\n",
    "\n",
    "Adapted from Google Keras code example [Image classification from scratch](https://keras.io/examples/vision/image_classification_from_scratch/)\n",
    "\n",
    " - Load libraries\n",
    " - Getting the data\n",
    " - Preprocessing\n",
    "    - Standard image size\n",
    "    - Splitting to train/test\n",
    " - Train a CNN and evaluate the results\n",
    " - Try the model on a new data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pydot # NOTE: need graphviz installed in the system\n",
    "import hashlib\n",
    "import shutil\n",
    "\n",
    "# Constants\n",
    "ZIP_HASH = '14b8b6eb4ec7172708a1eae4c3313a009722ecf8'\n",
    "IMAGE_SIZE = (180, 180)\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the image datasets\n",
    "\n",
    "All image datasets will be stored in the `3-image_classification/animals` folder\n",
    "\n",
    "## Option 1 - download zip from data.badmath.org\n",
    "\n",
    "This is enabled in the next cell.\n",
    "\n",
    "1. Download zip from data.badmath.org\n",
    "2. Unzip folder\n",
    "3. Delete zip file\n",
    "\n",
    "\n",
    "## Option 2 - manual download from kaggle\n",
    "\n",
    "This will take some downloading, unzipping, and moving/renaming files and folders.\n",
    "\n",
    "### \"Cat and Dog\"\n",
    "1. Download the dataset from https://www.kaggle.com/datasets/tongpython/cat-and-dog\n",
    "2. Move the zip into the `animals` folder\n",
    "3. Unzip it, I've called the folder `animals/cat_and_dog`\n",
    "4. You should have images such as `animals/cat_and_dog/test_set/cats/cat.4001.jpg`\n",
    "\n",
    "### \"Animal Image Dataset\"\n",
    "1. Download the dataset from https://www.kaggle.com/datasets/ashishsaxena2209/animal-image-datasetdog-cat-and-panda\n",
    "2. Move the zip into the `animals` folder\n",
    "3. Unzip it, I've called the folder `animals/animal_images`\n",
    "4. You should have images such as `animals/animal_images/cats/cats_00001.jpg`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download image datasets\n",
    "\n",
    "# Skip this if you've already got a directory called 'animals' (e.g. if you've run this before)\n",
    "if not os.path.exists('animals'):\n",
    "    # Use curl to download the zip if it's not already there\n",
    "    if not os.path.exists('animals.zip'):\n",
    "        !curl -L -o animals.zip 'https://data.badmath.org/animals.zip'\n",
    "    \n",
    "    hash = hashlib.sha1(open('animals.zip', 'rb').read()).hexdigest()\n",
    "    if (hash == ZIP_HASH):\n",
    "        print('✅ Download hash validated')\n",
    "    else:\n",
    "        raise Exception('❌ ERROR: Download hash does not match!')\n",
    "\n",
    "\n",
    "    # Unzip the downloaded file into `animals`\n",
    "    os.mkdir('animals')\n",
    "    shutil.unpack_archive('animals.zip', 'animals')\n",
    "\n",
    "    os.remove('animals.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for corrupted images\n",
    "train = 'animals/cat_and_dog/training_set/'\n",
    "valid = 'animals/cat_and_dog/test_set/'\n",
    "world = 'animals/animal_images/'\n",
    "\n",
    "num_skipped = 0\n",
    "for data_dir in (train, valid, world):\n",
    "    for animal in os.listdir(data_dir):\n",
    "        if os.path.isdir(os.path.join(data_dir, animal)):\n",
    "            folder_path = os.path.join(data_dir, animal)\n",
    "            for fname in os.listdir(folder_path):\n",
    "                fpath = os.path.join(folder_path, fname)\n",
    "                try:\n",
    "                    fobj = open(fpath, \"rb\")\n",
    "                    is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "                finally:\n",
    "                    fobj.close()\n",
    "\n",
    "                if not is_jfif:\n",
    "                    num_skipped += 1\n",
    "                    print(\"Deleted %s\" % fpath)\n",
    "                    # Delete corrupted image\n",
    "                    os.remove(fpath)\n",
    "\n",
    "\n",
    "print(\"Deleted %d images\" % num_skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the class names\n",
    "class_names = os.listdir(train)\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train,\n",
    "    subset=None,\n",
    "    seed=1337,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "train_ds = train_ds.map(lambda x, y: (x, tf.one_hot(y, NUM_CLASSES)))\n",
    "\n",
    "valid_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    valid,\n",
    "    subset=None,\n",
    "    seed=1337,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "valid_ds = valid_ds.map(lambda x, y: (x, tf.one_hot(y, NUM_CLASSES)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[tf.argmax(labels[i])])\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model\n",
    "\n",
    "This code defines a convolutional neural network (CNN) using the Keras library. The network architecture consists of multiple blocks of separable convolutional layers, with residual connections between the blocks. The last layer is a dense layer with either sigmoid or softmax activation, depending on the number of classes. The model is created by calling the make_model function with the input shape and number of classes as arguments, and the resulting model is plotted using keras.utils.plot_model.\n",
    "\n",
    "This is a simplified version of the Xception architecture (https://arxiv.org/abs/1610.02357).\n",
    " - keras.Input(shape=input_shape) creates an input layer with the specified input shape.\n",
    " - layers.Rescaling(1.0 / 255) rescales the input values by dividing them by 255.\n",
    " - layers.Conv2D(128, 3, strides=2, padding=\"same\") creates a 2D convolutional layer with 128 filters, a kernel size of 3x3, a stride of 2, and same padding.\n",
    " - layers.BatchNormalization() normalizes the outputs of the previous layer to speed up training and reduce overfitting.\n",
    " - layers.Activation(\"relu\") applies the ReLU activation function to the previous layer's outputs.\n",
    " - layers.SeparableConv2D(size, 3, padding=\"same\") creates a depthwise separable convolutional layer with size filters, a kernel size of 3x3, and same padding.\n",
    " - layers.MaxPooling2D(3, strides=2, padding=\"same\") applies max pooling to the previous layer's outputs, reducing their size by a factor of 2.\n",
    " - layers.Conv2D(size, 1, strides=2, padding=\"same\") creates a 2D convolutional layer with size filters, a kernel size of 1x1, a stride of 2, and same padding.\n",
    " - layers.add([x, residual]) adds the outputs of the previous layer and the residual layer.\n",
    " - layers.GlobalAveragePooling2D() calculates the average of each feature map in the previous layer's outputs.\n",
    " - layers.Dropout(0.5) randomly drops out 50% of the previous layer's outputs during training to reduce overfitting.\n",
    " - layers.Dense(units, activation=activation) creates a fully connected layer with units output nodes and the specified activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model\n",
    "# This is a simplified version of the Xception architecture (https://arxiv.org/abs/1610.02357).\n",
    "\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "# model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
    "model = make_model(input_shape=image_size + (3,), num_classes=3)\n",
    "\n",
    "# Uncomment to show model summary plot\n",
    "# keras.utils.plot_model(model, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    # loss=\"binary_crossentropy\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=valid_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with 100% more plotting!\n",
    "# Plot the learning curves\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(f\"Validation loss: {val_loss:.2f}\")\n",
    "print(f\"Validation accuracy: {val_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the (cat, dog, panda) dataset\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"path/to/panda/dataset\",\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "test_ds = test_ds.prefetch(buffer_size=32)\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on a new image\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    '{{test}}/cats/cat.4001.jpg',\n",
    "    target_size=image_size\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = float(predictions[0])\n",
    "print(f\"This image is {100 * (1 - score):.2f}% cat and {100 * score:.2f}% dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images\n",
    "\n",
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
